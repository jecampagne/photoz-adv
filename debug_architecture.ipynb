{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hiddenlayer as hl\n",
    "from modelsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_summary\n",
      "  Downloading torch_summary-1.3.3-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: torch-summary\n",
      "Successfully installed torch-summary-1.3.3\n"
     ]
    }
   ],
   "source": [
    "#use pip install here to load missing stuff\n",
    "#! pip install modelsummary\n",
    "#!pip install torch_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb with torch_summary recent version, there is something funny as you have to import torchsummary...\n",
    "from torchsummary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "#well the 9/July/20 with recent Catalina install and so on I get 1.4.0, \n",
    "# previously I was running 1.1.0\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class TorchSummarizeDf(object):\n",
    "    def __init__(self, model, weights=False, input_shape=True, nb_trainable=False, debug=False):\n",
    "        \"\"\"\n",
    "        Summarizes torch model by showing trainable parameters and weights.\n",
    "\n",
    "        author: wassname\n",
    "        url: https://gist.github.com/wassname/0fb8f95e4272e6bdd27bd7df386716b7\n",
    "        license: MIT\n",
    "\n",
    "        Modified from:\n",
    "        - https://github.com/pytorch/pytorch/issues/2001#issuecomment-313735757\n",
    "        - https://gist.github.com/wassname/0fb8f95e4272e6bdd27bd7df386716b7/\n",
    "\n",
    "        Usage:\n",
    "            import torchvision.models as models\n",
    "            model = models.alexnet()\n",
    "            # attach temporary hooks using `with`\n",
    "            with TorchSummarizeDf(model) as tdf:\n",
    "                x = Variable(torch.rand(2, 3, 224, 224))\n",
    "                y = model(x)\n",
    "                df = tdf.make_df()\n",
    "            print(df)\n",
    "\n",
    "            # Total parameters 61100840\n",
    "            #              name class_name        input_shape       output_shape  nb_params\n",
    "            # 1     features=>0     Conv2d  (-1, 3, 224, 224)   (-1, 64, 55, 55)      23296\n",
    "            # 2     features=>1       ReLU   (-1, 64, 55, 55)   (-1, 64, 55, 55)          0\n",
    "            # ...\n",
    "        \"\"\"\n",
    "        # Names are stored in parent and path+name is unique not the name\n",
    "        self.names = get_names_dict(model)\n",
    "\n",
    "        # store arguments\n",
    "        self.model = model\n",
    "        self.weights = weights\n",
    "        self.input_shape = input_shape\n",
    "        self.nb_trainable = nb_trainable\n",
    "        self.debug = debug\n",
    "\n",
    "        # create properties\n",
    "        self.summary = OrderedDict()\n",
    "        self.hooks = []\n",
    "\n",
    "    def register_hook(self, module):\n",
    "        \"\"\"Register hooks recursively\"\"\"\n",
    "        self.hooks.append(module.register_forward_hook(self.hook))\n",
    "\n",
    "    def hook(self, module, input, output):\n",
    "        \"\"\"This hook is applied when each module is run\"\"\"\n",
    "        class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "        module_idx = len(self.summary)\n",
    "        \n",
    "        name = None\n",
    "        for key, item in self.names.items():\n",
    "            if item == module:\n",
    "                name = key\n",
    "        if name is None:\n",
    "            name = '{}_{}'.format(class_name, module_idx)\n",
    "\n",
    "        m_key = module_idx + 1\n",
    "\n",
    "        self.summary[m_key] = OrderedDict()\n",
    "        self.summary[m_key]['name'] = name\n",
    "        self.summary[m_key]['class_name'] = class_name\n",
    "\n",
    "        # Handle multiple inputs\n",
    "        if self.input_shape:\n",
    "            # for each input remove batch size and replace with one\n",
    "            self.summary[m_key][\n",
    "                'input_shape'] = format_input_output_shape(input)\n",
    "\n",
    "        # Handle multiple outputs\n",
    "        self.summary[m_key]['output_shape'] = format_input_output_shape(output)\n",
    "\n",
    "        if self.weights:\n",
    "            self.summary[m_key]['weights'] = list(\n",
    "                [tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        if self.nb_trainable:\n",
    "            self.summary[m_key]['nb_trainable'] = get_params(module, True)\n",
    "            \n",
    "        self.summary[m_key]['nb_params'] = get_params(module, True)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(self.summary[m_key])\n",
    "\n",
    "    def __enter__(self):\n",
    "\n",
    "        # register hook\n",
    "        self.model.apply(self.register_hook)\n",
    "\n",
    "        # make a forward pass\n",
    "        self.training = self.model.training\n",
    "        if self.training:\n",
    "            self.model.eval()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def make_df(self):\n",
    "        \"\"\"Make dataframe.\"\"\"\n",
    "        df = pd.DataFrame.from_dict(self.summary, orient='index')\n",
    "\n",
    "        df['level'] = df['name'].apply(lambda name: name.count('.'))\n",
    "        \n",
    "        total_params = get_params(self.model, False)\n",
    "        total_trainable_params = get_params(self.model, True)\n",
    "        print('Total parameters', total_params)\n",
    "        print('Total trainable parameters', total_trainable_params)\n",
    "        return df\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "\n",
    "        if exc_type or exc_val or exc_tb:\n",
    "            # to help with debugging your model lets print the summary even if it fails\n",
    "            df_summary = pd.DataFrame.from_dict(self.summary, orient='index')\n",
    "            print(df_summary)\n",
    "\n",
    "        if self.training:\n",
    "            self.model.train()\n",
    "\n",
    "        # remove these hooks\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "\n",
    "\n",
    "def get_names_dict(model):\n",
    "    \"\"\"Recursive walk to get names including path.\"\"\"\n",
    "    names = {}\n",
    "\n",
    "    def _get_names(module, parent_name=''):\n",
    "        for key, module in module.named_children():\n",
    "            name = parent_name + '.' + key if parent_name else key\n",
    "            names[name] = module\n",
    "            if isinstance(module, torch.nn.Module):\n",
    "                _get_names(module, parent_name=name)\n",
    "    _get_names(model)\n",
    "    return names\n",
    "\n",
    "def get_params(module, nb_trainable=False):\n",
    "    if nb_trainable:\n",
    "        params = sum([torch.LongTensor(list(p.size())).prod() for p in module.parameters() if p.requires_grad])\n",
    "    else:\n",
    "        params = sum([torch.LongTensor(list(p.size())).prod() for p in module.parameters()])\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        params = params.item()\n",
    "    return params\n",
    "\n",
    "def format_input_output_shape(tensors):\n",
    "    \"Recursively get N nested levels of inputs.\"\"\"\n",
    "    def _format_input_output_shape(tensors):\n",
    "        if isinstance(tensors, (list, tuple)):\n",
    "            if len(tensors)==1:\n",
    "                return _format_input_output_shape(tensors[0])\n",
    "            else:\n",
    "                return [_format_input_output_shape(tensor) for tensor in tensors]\n",
    "        else:\n",
    "            return [(-1, ) + tuple(tensors.size())[1:]]\n",
    "    return _format_input_output_shape(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PzConv2d(nn.Module):\n",
    "    \"\"\" Convolution 2D Layer followed by PReLU activation\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in_channels, n_out_channels, **kwargs):\n",
    "        super(PzConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_in_channels, n_out_channels, bias=True,\n",
    "                            **kwargs)\n",
    "        ## JEC 11/9/19 use default init :\n",
    "        ##   kaiming_uniform_ for weights\n",
    "        ##   bias uniform \n",
    "        #xavier init for the weights\n",
    "        ## nn.init.xavier_normal_(self.conv.weight)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "        ## constant init for the biais with cte=0.1\n",
    "        nn.init.constant_(self.conv.bias,0.1)\n",
    "####        self.bn = nn.BatchNorm2d(n_out_channels, eps=0.001)  #### TEST JEC 4/11/19 for robust training\n",
    "        self.activ = nn.PReLU(num_parameters=n_out_channels, init=0.25)\n",
    "        ## self.activ = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "####        x = self.bn(x) #### TEST JEC 4/11/19 for robust training\n",
    "        return self.activ(x)\n",
    "\n",
    "\n",
    "class PzPool2d(nn.Module):\n",
    "    \"\"\" Average Pooling Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride, padding=0):\n",
    "        super(PzPool2d, self).__init__()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=kernel_size,\n",
    "                                 stride=stride,\n",
    "                                 padding=padding,\n",
    "                                 ceil_mode=True,\n",
    "                                 count_include_pad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pool(x)\n",
    "\n",
    "\n",
    "class PzFullyConnected(nn.Module):\n",
    "    \"\"\" Dense or Fully Connected Layer followed by ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, n_outputs, withrelu=True, **kwargs):\n",
    "        super(PzFullyConnected, self).__init__()\n",
    "        self.withrelu = withrelu\n",
    "        self.linear = nn.Linear(n_inputs, n_outputs, bias=True)\n",
    "        ## JEC 11/9/19 use default init :\n",
    "        ##   kaiming_uniform_ for weights\n",
    "        ##   bias uniform \n",
    "\n",
    "        # xavier init for the weights\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "##        nn.init.xavier_normal_(self.linear.weight)\n",
    "        # constant init for the biais with cte=0.1\n",
    "        nn.init.constant_(self.linear.bias, 0.1)\n",
    "        self.activ = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.withrelu:\n",
    "            x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PzInception(nn.Module):\n",
    "    \"\"\" Inspection module\n",
    "\n",
    "        The input (x) is dispatched between\n",
    "\n",
    "        o a cascade of conv layers s1_0 1x1 , s2_0 3x3\n",
    "        o a cascade of conv layer s1_2 1x1, followed by pooling layer pool0 2x2\n",
    "        o a cascade of conv layer s2_2 1x1\n",
    "        o optionally a cascade of conv layers s1_1 1x1, s2_1 5x5\n",
    "\n",
    "        then the 3 (or 4) intermediate outputs are concatenated\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in_channels, n_out_channels_1, n_out_channels_2,\n",
    "                 without_kernel_5=False, debug=False):\n",
    "        super(PzInception, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.s1_0 = PzConv2d(n_in_channels, n_out_channels_1,\n",
    "                             kernel_size=1, padding=0)\n",
    "        self.s2_0 = PzConv2d(n_out_channels_1, n_out_channels_2,\n",
    "                             kernel_size=3, padding=1)\n",
    "\n",
    "        self.s1_2 = PzConv2d(n_in_channels, n_out_channels_1, kernel_size=1)\n",
    "        self.pad0 = nn.ZeroPad2d([0, 1, 0, 1])\n",
    "        self.pool0 = PzPool2d(kernel_size=2, stride=1, padding=0)\n",
    "\n",
    "        self.without_kernel_5 = without_kernel_5\n",
    "        if not (without_kernel_5):\n",
    "            self.s1_1 = PzConv2d(n_in_channels, n_out_channels_1,\n",
    "                                 kernel_size=1, padding=0)\n",
    "            self.s2_1 = PzConv2d(n_out_channels_1, n_out_channels_2,\n",
    "                                 kernel_size=5, padding=2)\n",
    "\n",
    "        self.s2_2 = PzConv2d(n_in_channels, n_out_channels_2, kernel_size=1,\n",
    "                             padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x:image tenseur N_batch, Channels, Height, Width\n",
    "        x_s1_0 = self.s1_0(x)\n",
    "        x_s2_0 = self.s2_0(x_s1_0)\n",
    "\n",
    "        x_s1_2 = self.s1_2(x)\n",
    "\n",
    "        x_pool0 = self.pool0(self.pad0(x_s1_2))\n",
    "\n",
    "        if not (self.without_kernel_5):\n",
    "            x_s1_1 = self.s1_1(x)\n",
    "            x_s2_1 = self.s2_1(x_s1_1)\n",
    "\n",
    "        x_s2_2 = self.s2_2(x)\n",
    "\n",
    "        if self.debug: print(\"Inception x_s1_0  :\", x_s1_0.size())\n",
    "        if self.debug: print(\"Inception x_s2_0  :\", x_s2_0.size())\n",
    "        if self.debug: print(\"Inception x_s1_2  :\", x_s1_2.size())\n",
    "        if self.debug: print(\"Inception x_pool0 :\", x_pool0.size())\n",
    "\n",
    "        if not (self.without_kernel_5) and self.debug:\n",
    "            print(\"Inception x_s1_1  :\", x_s1_1.size())\n",
    "            print(\"Inception x_s2_1  :\", x_s2_1.size())\n",
    "\n",
    "        if self.debug: print(\"Inception x_s2_2  :\", x_s2_2.size())\n",
    "\n",
    "        # to be check: dim=1=> NCHW (en TensorFlow axis=3 NHWC)\n",
    "        if not (self.without_kernel_5):\n",
    "            output = torch.cat((x_s2_2, x_s2_1, x_s2_0, x_pool0), dim=1)\n",
    "        else:\n",
    "            output = torch.cat((x_s2_2, x_s2_0, x_pool0), dim=1)\n",
    "\n",
    "        if self.debug: print(\"Inception output :\", output.shape)\n",
    "        return output\n",
    "\n",
    "\n",
    "class NetWithInception(nn.Module):\n",
    "    \"\"\" The Networks\n",
    "        inputs: the image (x), the reddening vector\n",
    "\n",
    "\n",
    "        The image 64x64x5 is fed forwardly throw\n",
    "        o a conv layer 5x5\n",
    "        o a pooling layer 2x2\n",
    "        o 5 inspection modules with the last one including a 5x5 part\n",
    "\n",
    "        Then, we concatenate the result with the reddening vector to perform\n",
    "        o 3 fully connected layers\n",
    "\n",
    "        The output dimension is given by n_bins\n",
    "        There is no activation softmax here to allow the use of Cross Entropy loss\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_input_channels, debug=False):\n",
    "        super(NetWithInception, self).__init__()\n",
    "        \n",
    "        # the number of bins to represent the output photo-z\n",
    "        self.n_bins = 180\n",
    "\n",
    "        self.debug = debug\n",
    "        self.conv0 = PzConv2d(n_in_channels=n_input_channels,\n",
    "                              n_out_channels=64,\n",
    "                              kernel_size=5, padding=2)\n",
    "        self.pool0 = PzPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # for the Softmax the input tensor shape is [1,n] so apply on axis=1\n",
    "        # t1 = torch.rand([1,10])\n",
    "        # t2 = nn.Softmax(dim=1)(t1)\n",
    "        # torch.sum(t2) = 1\n",
    "        self.i0 = PzInception(n_in_channels=64,\n",
    "                              n_out_channels_1=48,\n",
    "                              n_out_channels_2=64)\n",
    "\n",
    "        self.i1 = PzInception(n_in_channels=240,\n",
    "                              n_out_channels_1=64,\n",
    "                              n_out_channels_2=92)\n",
    "\n",
    "        self.i2 = PzInception(n_in_channels=340,\n",
    "                              n_out_channels_1=92,\n",
    "                              n_out_channels_2=128)\n",
    "\n",
    "        self.i3 = PzInception(n_in_channels=476,\n",
    "                              n_out_channels_1=92,\n",
    "                              n_out_channels_2=128)\n",
    "\n",
    "        self.i4 = PzInception(n_in_channels=476,\n",
    "                              n_out_channels_1=92,\n",
    "                              n_out_channels_2=128,\n",
    "                              without_kernel_5=True)\n",
    "\n",
    "        self.fc0 = PzFullyConnected(n_inputs=22273, n_outputs=1096)\n",
    "        self.fc1 = PzFullyConnected(n_inputs=1096, n_outputs=1096)\n",
    "        self.fc2 = PzFullyConnected(n_inputs=1096, n_outputs=self.n_bins)\n",
    "\n",
    "\n",
    "        # NOT USED self.activ = nn.Softmax(dim=1)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: the input\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        the totale number of features = number of elements of the tensor except the batch dimension\n",
    "\n",
    "        \"\"\"\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    def forward(self, x, reddening):\n",
    "        # x:image tenseur N_batch, Channels, Height, Width\n",
    "        #    size N, Channles=5 filtres, H,W = 64 pixels\n",
    "        # save original image\n",
    "        x_in = x\n",
    "\n",
    "        if self.debug: print(\"input shape: \", x.size())\n",
    "        x = self.conv0(x)\n",
    "        if self.debug: print(\"conv0 shape: \", x.size())\n",
    "        x = self.pool0(x)\n",
    "        if self.debug: print(\"conv0p shape: \", x.size())\n",
    "        if self.debug: print('>>>>>>> i0:START <<<<<<<')\n",
    "        x = self.i0(x)\n",
    "        if self.debug: print(\"i0 shape: \", x.size())\n",
    "\n",
    "        if self.debug: print('>>>>>>> i1:START <<<<<<<')\n",
    "        x = self.i1(x)\n",
    "\n",
    "        x = self.pool0(x)\n",
    "        if self.debug: print(\"i1p shape: \", x.size())\n",
    "\n",
    "        if self.debug: print('>>>>>>> i2:START <<<<<<<')\n",
    "        x = self.i2(x)\n",
    "        if self.debug: print(\"i2 shape: \", x.size())\n",
    "\n",
    "        if self.debug: print('>>>>>>> i3:START <<<<<<<')\n",
    "        x = self.i3(x)\n",
    "        x = self.pool0(x)\n",
    "        if self.debug: print(\"i3p shape: \", x.size())\n",
    "\n",
    "        if self.debug: print('>>>>>>> i4:START <<<<<<<')\n",
    "        x = self.i4(x)\n",
    "        if self.debug: print(\"i4 shape: \", x.size())\n",
    "\n",
    "        if self.debug: print('>>>>>>> FC part :START <<<<<<<')\n",
    "        flat = x.view(-1, self.num_flat_features(x))\n",
    "        if self.debug: print(\"flat shape: \", flat.size())\n",
    "        concat = torch.cat((flat, reddening), dim=1)\n",
    "        if self.debug: print('concat shape: ', concat.size())\n",
    "\n",
    "        fcn_in_features = concat.size(-1)\n",
    "        if self.debug: print('fcn_in_features: ', fcn_in_features)\n",
    "\n",
    "        x = self.fc0(concat)\n",
    "        if self.debug: print('fc0 shape: ', x.size())\n",
    "        x = self.fc1(x)\n",
    "        if self.debug: print('fc1 shape: ', x.size())\n",
    "        x = self.fc2(x)\n",
    "        if self.debug: print('fc2 shape: ', x.size())\n",
    "\n",
    "        output = x\n",
    "        if self.debug: print('output shape: ', output.size())\n",
    "\n",
    "        #params = {\"output\": output, \"x\": x_in, \"reddening\": reddening}\n",
    "        # return params\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs type  tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "reds type  tensor([[0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0657, 0.0000, 0.2177, 0.2044, 0.0000, 0.3166, 0.0000, 0.1636,\n",
       "         0.0000, 0.6220, 0.6150, 0.3405, 0.0000, 0.2703, 0.5066, 0.8436, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1488, 0.0000, 0.7297, 0.2758, 0.1792, 0.3298,\n",
       "         0.2027, 0.0000, 0.6762, 0.0000, 0.0000, 0.2527, 0.4238, 0.6653, 0.5161,\n",
       "         0.2086, 0.3348, 0.1913, 0.6936, 0.9309, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.4789, 0.5011, 0.6674, 0.0000, 0.4496, 0.1870, 0.0000, 0.4666, 0.5541,\n",
       "         0.1733, 0.2116, 0.1581, 0.0000, 0.5077, 0.3456, 0.0452, 0.8888, 0.3231,\n",
       "         0.2593, 0.8986, 0.4276, 0.0762, 0.0000, 0.0000, 0.0000, 0.0000, 0.9535,\n",
       "         0.0000, 0.0032, 0.0293, 0.0000, 0.5244, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0072, 0.0000, 0.4104, 0.5847, 0.3495, 0.0924, 0.2245, 0.9298,\n",
       "         0.3138, 0.4660, 0.0000, 0.0000, 0.0000, 0.6302, 0.0000, 0.2351, 0.0742,\n",
       "         0.0000, 0.1796, 0.0000, 0.1867, 0.0000, 0.0000, 0.0000, 0.3743, 0.7002,\n",
       "         0.0000, 0.0000, 0.2626, 0.8103, 0.2579, 0.0000, 0.5431, 0.0000, 0.0000,\n",
       "         1.1594, 0.1929, 0.0512, 0.0000, 0.0000, 1.1441, 0.8461, 0.1368, 0.4445,\n",
       "         0.0000, 0.3055, 0.0524, 0.0000, 0.5694, 0.0642, 0.7137, 0.0000, 0.7634,\n",
       "         0.3167, 0.0000, 0.0000, 0.0000, 0.3873, 0.2454, 0.3359, 0.0000, 0.5161,\n",
       "         0.0600, 0.0000, 0.0000, 0.0000, 0.0052, 0.0000, 1.0235, 0.0000, 0.1951,\n",
       "         0.2562, 0.0000, 0.5982, 0.2885, 0.0000, 0.0000, 0.4803, 0.0000, 0.0000,\n",
       "         0.0000, 0.2303, 0.3450, 0.0000, 0.5314, 0.0282, 0.3584, 0.0000, 0.2389,\n",
       "         0.2114, 0.1352, 0.0000, 0.1393, 0.8035, 0.0000, 0.4255, 0.4620, 0.6611]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_channels = 5\n",
    "img_H = 64\n",
    "img_W = 64\n",
    "n_batchs = 1\n",
    "model = NetWithInception(img_channels,debug=False)\n",
    "#Notice that if dtype=torch.double ca plente\n",
    "imgs = torch.zeros([n_batchs, img_channels,img_H ,img_W],dtype=torch.float)\n",
    "reds = torch.zeros([n_batchs,1],dtype=torch.float)\n",
    "print(\"imgs type \",imgs)\n",
    "print(\"reds type \",reds)\n",
    "model(imgs,reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetWithInception(\n",
      "  (conv0): PzConv2d(\n",
      "    (conv): Conv2d(5, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (activ): PReLU(num_parameters=64)\n",
      "  )\n",
      "  (pool0): PzPool2d(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (i0): PzInception(\n",
      "    (s1_0): PzConv2d(\n",
      "      (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=48)\n",
      "    )\n",
      "    (s2_0): PzConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activ): PReLU(num_parameters=64)\n",
      "    )\n",
      "    (s1_2): PzConv2d(\n",
      "      (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=48)\n",
      "    )\n",
      "    (pad0): ZeroPad2d(padding=[0, 1, 0, 1], value=0.0)\n",
      "    (pool0): PzPool2d(\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (s1_1): PzConv2d(\n",
      "      (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=48)\n",
      "    )\n",
      "    (s2_1): PzConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (activ): PReLU(num_parameters=64)\n",
      "    )\n",
      "    (s2_2): PzConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=64)\n",
      "    )\n",
      "  )\n",
      "  (i1): PzInception(\n",
      "    (s1_0): PzConv2d(\n",
      "      (conv): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=64)\n",
      "    )\n",
      "    (s2_0): PzConv2d(\n",
      "      (conv): Conv2d(64, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s1_2): PzConv2d(\n",
      "      (conv): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=64)\n",
      "    )\n",
      "    (pad0): ZeroPad2d(padding=[0, 1, 0, 1], value=0.0)\n",
      "    (pool0): PzPool2d(\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (s1_1): PzConv2d(\n",
      "      (conv): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=64)\n",
      "    )\n",
      "    (s2_1): PzConv2d(\n",
      "      (conv): Conv2d(64, 92, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s2_2): PzConv2d(\n",
      "      (conv): Conv2d(240, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "  )\n",
      "  (i2): PzInception(\n",
      "    (s1_0): PzConv2d(\n",
      "      (conv): Conv2d(340, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s2_0): PzConv2d(\n",
      "      (conv): Conv2d(92, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "    (s1_2): PzConv2d(\n",
      "      (conv): Conv2d(340, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (pad0): ZeroPad2d(padding=[0, 1, 0, 1], value=0.0)\n",
      "    (pool0): PzPool2d(\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (s1_1): PzConv2d(\n",
      "      (conv): Conv2d(340, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s2_1): PzConv2d(\n",
      "      (conv): Conv2d(92, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "    (s2_2): PzConv2d(\n",
      "      (conv): Conv2d(340, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "  )\n",
      "  (i3): PzInception(\n",
      "    (s1_0): PzConv2d(\n",
      "      (conv): Conv2d(476, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s2_0): PzConv2d(\n",
      "      (conv): Conv2d(92, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "    (s1_2): PzConv2d(\n",
      "      (conv): Conv2d(476, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (pad0): ZeroPad2d(padding=[0, 1, 0, 1], value=0.0)\n",
      "    (pool0): PzPool2d(\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (s1_1): PzConv2d(\n",
      "      (conv): Conv2d(476, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s2_1): PzConv2d(\n",
      "      (conv): Conv2d(92, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "    (s2_2): PzConv2d(\n",
      "      (conv): Conv2d(476, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "  )\n",
      "  (i4): PzInception(\n",
      "    (s1_0): PzConv2d(\n",
      "      (conv): Conv2d(476, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (s2_0): PzConv2d(\n",
      "      (conv): Conv2d(92, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "    (s1_2): PzConv2d(\n",
      "      (conv): Conv2d(476, 92, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=92)\n",
      "    )\n",
      "    (pad0): ZeroPad2d(padding=[0, 1, 0, 1], value=0.0)\n",
      "    (pool0): PzPool2d(\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (s2_2): PzConv2d(\n",
      "      (conv): Conv2d(476, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (activ): PReLU(num_parameters=128)\n",
      "    )\n",
      "  )\n",
      "  (fc0): PzFullyConnected(\n",
      "    (linear): Linear(in_features=22273, out_features=1096, bias=True)\n",
      "    (activ): ReLU()\n",
      "  )\n",
      "  (fc1): PzFullyConnected(\n",
      "    (linear): Linear(in_features=1096, out_features=1096, bias=True)\n",
      "    (activ): ReLU()\n",
      "  )\n",
      "  (fc2): PzFullyConnected(\n",
      "    (linear): Linear(in_features=1096, out_features=180, bias=True)\n",
      "    (activ): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 27596372\n",
      "Total trainable parameters 27596372\n",
      "                     name        class_name                     input_shape  \\\n",
      "1              conv0.conv            Conv2d               [(-1, 5, 64, 64)]   \n",
      "2             conv0.activ             PReLU              [(-1, 64, 64, 64)]   \n",
      "3                   conv0          PzConv2d               [(-1, 5, 64, 64)]   \n",
      "4              pool0.pool         AvgPool2d              [(-1, 64, 64, 64)]   \n",
      "5                   pool0          PzPool2d              [(-1, 64, 64, 64)]   \n",
      "6            i0.s1_0.conv            Conv2d              [(-1, 64, 32, 32)]   \n",
      "7           i0.s1_0.activ             PReLU              [(-1, 48, 32, 32)]   \n",
      "8                 i0.s1_0          PzConv2d              [(-1, 64, 32, 32)]   \n",
      "9            i0.s2_0.conv            Conv2d              [(-1, 48, 32, 32)]   \n",
      "10          i0.s2_0.activ             PReLU              [(-1, 64, 32, 32)]   \n",
      "11                i0.s2_0          PzConv2d              [(-1, 48, 32, 32)]   \n",
      "12           i0.s1_2.conv            Conv2d              [(-1, 64, 32, 32)]   \n",
      "13          i0.s1_2.activ             PReLU              [(-1, 48, 32, 32)]   \n",
      "14                i0.s1_2          PzConv2d              [(-1, 64, 32, 32)]   \n",
      "15                i0.pad0         ZeroPad2d              [(-1, 48, 32, 32)]   \n",
      "16          i0.pool0.pool         AvgPool2d              [(-1, 48, 33, 33)]   \n",
      "17               i0.pool0          PzPool2d              [(-1, 48, 33, 33)]   \n",
      "18           i0.s1_1.conv            Conv2d              [(-1, 64, 32, 32)]   \n",
      "19          i0.s1_1.activ             PReLU              [(-1, 48, 32, 32)]   \n",
      "20                i0.s1_1          PzConv2d              [(-1, 64, 32, 32)]   \n",
      "21           i0.s2_1.conv            Conv2d              [(-1, 48, 32, 32)]   \n",
      "22          i0.s2_1.activ             PReLU              [(-1, 64, 32, 32)]   \n",
      "23                i0.s2_1          PzConv2d              [(-1, 48, 32, 32)]   \n",
      "24           i0.s2_2.conv            Conv2d              [(-1, 64, 32, 32)]   \n",
      "25          i0.s2_2.activ             PReLU              [(-1, 64, 32, 32)]   \n",
      "26                i0.s2_2          PzConv2d              [(-1, 64, 32, 32)]   \n",
      "27                     i0       PzInception              [(-1, 64, 32, 32)]   \n",
      "28           i1.s1_0.conv            Conv2d             [(-1, 240, 32, 32)]   \n",
      "29          i1.s1_0.activ             PReLU              [(-1, 64, 32, 32)]   \n",
      "30                i1.s1_0          PzConv2d             [(-1, 240, 32, 32)]   \n",
      "31           i1.s2_0.conv            Conv2d              [(-1, 64, 32, 32)]   \n",
      "32          i1.s2_0.activ             PReLU              [(-1, 92, 32, 32)]   \n",
      "33                i1.s2_0          PzConv2d              [(-1, 64, 32, 32)]   \n",
      "34           i1.s1_2.conv            Conv2d             [(-1, 240, 32, 32)]   \n",
      "35          i1.s1_2.activ             PReLU              [(-1, 64, 32, 32)]   \n",
      "36                i1.s1_2          PzConv2d             [(-1, 240, 32, 32)]   \n",
      "37                i1.pad0         ZeroPad2d              [(-1, 64, 32, 32)]   \n",
      "38          i1.pool0.pool         AvgPool2d              [(-1, 64, 33, 33)]   \n",
      "39               i1.pool0          PzPool2d              [(-1, 64, 33, 33)]   \n",
      "40           i1.s1_1.conv            Conv2d             [(-1, 240, 32, 32)]   \n",
      "41          i1.s1_1.activ             PReLU              [(-1, 64, 32, 32)]   \n",
      "42                i1.s1_1          PzConv2d             [(-1, 240, 32, 32)]   \n",
      "43           i1.s2_1.conv            Conv2d              [(-1, 64, 32, 32)]   \n",
      "44          i1.s2_1.activ             PReLU              [(-1, 92, 32, 32)]   \n",
      "45                i1.s2_1          PzConv2d              [(-1, 64, 32, 32)]   \n",
      "46           i1.s2_2.conv            Conv2d             [(-1, 240, 32, 32)]   \n",
      "47          i1.s2_2.activ             PReLU              [(-1, 92, 32, 32)]   \n",
      "48                i1.s2_2          PzConv2d             [(-1, 240, 32, 32)]   \n",
      "49                     i1       PzInception             [(-1, 240, 32, 32)]   \n",
      "50             pool0.pool         AvgPool2d             [(-1, 340, 32, 32)]   \n",
      "51                  pool0          PzPool2d             [(-1, 340, 32, 32)]   \n",
      "52           i2.s1_0.conv            Conv2d             [(-1, 340, 16, 16)]   \n",
      "53          i2.s1_0.activ             PReLU              [(-1, 92, 16, 16)]   \n",
      "54                i2.s1_0          PzConv2d             [(-1, 340, 16, 16)]   \n",
      "55           i2.s2_0.conv            Conv2d              [(-1, 92, 16, 16)]   \n",
      "56          i2.s2_0.activ             PReLU             [(-1, 128, 16, 16)]   \n",
      "57                i2.s2_0          PzConv2d              [(-1, 92, 16, 16)]   \n",
      "58           i2.s1_2.conv            Conv2d             [(-1, 340, 16, 16)]   \n",
      "59          i2.s1_2.activ             PReLU              [(-1, 92, 16, 16)]   \n",
      "60                i2.s1_2          PzConv2d             [(-1, 340, 16, 16)]   \n",
      "61                i2.pad0         ZeroPad2d              [(-1, 92, 16, 16)]   \n",
      "62          i2.pool0.pool         AvgPool2d              [(-1, 92, 17, 17)]   \n",
      "63               i2.pool0          PzPool2d              [(-1, 92, 17, 17)]   \n",
      "64           i2.s1_1.conv            Conv2d             [(-1, 340, 16, 16)]   \n",
      "65          i2.s1_1.activ             PReLU              [(-1, 92, 16, 16)]   \n",
      "66                i2.s1_1          PzConv2d             [(-1, 340, 16, 16)]   \n",
      "67           i2.s2_1.conv            Conv2d              [(-1, 92, 16, 16)]   \n",
      "68          i2.s2_1.activ             PReLU             [(-1, 128, 16, 16)]   \n",
      "69                i2.s2_1          PzConv2d              [(-1, 92, 16, 16)]   \n",
      "70           i2.s2_2.conv            Conv2d             [(-1, 340, 16, 16)]   \n",
      "71          i2.s2_2.activ             PReLU             [(-1, 128, 16, 16)]   \n",
      "72                i2.s2_2          PzConv2d             [(-1, 340, 16, 16)]   \n",
      "73                     i2       PzInception             [(-1, 340, 16, 16)]   \n",
      "74           i3.s1_0.conv            Conv2d             [(-1, 476, 16, 16)]   \n",
      "75          i3.s1_0.activ             PReLU              [(-1, 92, 16, 16)]   \n",
      "76                i3.s1_0          PzConv2d             [(-1, 476, 16, 16)]   \n",
      "77           i3.s2_0.conv            Conv2d              [(-1, 92, 16, 16)]   \n",
      "78          i3.s2_0.activ             PReLU             [(-1, 128, 16, 16)]   \n",
      "79                i3.s2_0          PzConv2d              [(-1, 92, 16, 16)]   \n",
      "80           i3.s1_2.conv            Conv2d             [(-1, 476, 16, 16)]   \n",
      "81          i3.s1_2.activ             PReLU              [(-1, 92, 16, 16)]   \n",
      "82                i3.s1_2          PzConv2d             [(-1, 476, 16, 16)]   \n",
      "83                i3.pad0         ZeroPad2d              [(-1, 92, 16, 16)]   \n",
      "84          i3.pool0.pool         AvgPool2d              [(-1, 92, 17, 17)]   \n",
      "85               i3.pool0          PzPool2d              [(-1, 92, 17, 17)]   \n",
      "86           i3.s1_1.conv            Conv2d             [(-1, 476, 16, 16)]   \n",
      "87          i3.s1_1.activ             PReLU              [(-1, 92, 16, 16)]   \n",
      "88                i3.s1_1          PzConv2d             [(-1, 476, 16, 16)]   \n",
      "89           i3.s2_1.conv            Conv2d              [(-1, 92, 16, 16)]   \n",
      "90          i3.s2_1.activ             PReLU             [(-1, 128, 16, 16)]   \n",
      "91                i3.s2_1          PzConv2d              [(-1, 92, 16, 16)]   \n",
      "92           i3.s2_2.conv            Conv2d             [(-1, 476, 16, 16)]   \n",
      "93          i3.s2_2.activ             PReLU             [(-1, 128, 16, 16)]   \n",
      "94                i3.s2_2          PzConv2d             [(-1, 476, 16, 16)]   \n",
      "95                     i3       PzInception             [(-1, 476, 16, 16)]   \n",
      "96             pool0.pool         AvgPool2d             [(-1, 476, 16, 16)]   \n",
      "97                  pool0          PzPool2d             [(-1, 476, 16, 16)]   \n",
      "98           i4.s1_0.conv            Conv2d               [(-1, 476, 8, 8)]   \n",
      "99          i4.s1_0.activ             PReLU                [(-1, 92, 8, 8)]   \n",
      "100               i4.s1_0          PzConv2d               [(-1, 476, 8, 8)]   \n",
      "101          i4.s2_0.conv            Conv2d                [(-1, 92, 8, 8)]   \n",
      "102         i4.s2_0.activ             PReLU               [(-1, 128, 8, 8)]   \n",
      "103               i4.s2_0          PzConv2d                [(-1, 92, 8, 8)]   \n",
      "104          i4.s1_2.conv            Conv2d               [(-1, 476, 8, 8)]   \n",
      "105         i4.s1_2.activ             PReLU                [(-1, 92, 8, 8)]   \n",
      "106               i4.s1_2          PzConv2d               [(-1, 476, 8, 8)]   \n",
      "107               i4.pad0         ZeroPad2d                [(-1, 92, 8, 8)]   \n",
      "108         i4.pool0.pool         AvgPool2d                [(-1, 92, 9, 9)]   \n",
      "109              i4.pool0          PzPool2d                [(-1, 92, 9, 9)]   \n",
      "110          i4.s2_2.conv            Conv2d               [(-1, 476, 8, 8)]   \n",
      "111         i4.s2_2.activ             PReLU               [(-1, 128, 8, 8)]   \n",
      "112               i4.s2_2          PzConv2d               [(-1, 476, 8, 8)]   \n",
      "113                    i4       PzInception               [(-1, 476, 8, 8)]   \n",
      "114            fc0.linear            Linear                   [(-1, 22273)]   \n",
      "115             fc0.activ              ReLU                    [(-1, 1096)]   \n",
      "116                   fc0  PzFullyConnected                   [(-1, 22273)]   \n",
      "117            fc1.linear            Linear                    [(-1, 1096)]   \n",
      "118             fc1.activ              ReLU                    [(-1, 1096)]   \n",
      "119                   fc1  PzFullyConnected                    [(-1, 1096)]   \n",
      "120            fc2.linear            Linear                    [(-1, 1096)]   \n",
      "121             fc2.activ              ReLU                     [(-1, 180)]   \n",
      "122                   fc2  PzFullyConnected                    [(-1, 1096)]   \n",
      "123  NetWithInception_122  NetWithInception  [[(-1, 5, 64, 64)], [(-1, 1)]]   \n",
      "\n",
      "            output_shape  nb_params  level  \n",
      "1     [(-1, 64, 64, 64)]       8064      1  \n",
      "2     [(-1, 64, 64, 64)]         64      1  \n",
      "3     [(-1, 64, 64, 64)]       8128      0  \n",
      "4     [(-1, 64, 32, 32)]          0      1  \n",
      "5     [(-1, 64, 32, 32)]          0      0  \n",
      "6     [(-1, 48, 32, 32)]       3120      2  \n",
      "7     [(-1, 48, 32, 32)]         48      2  \n",
      "8     [(-1, 48, 32, 32)]       3168      1  \n",
      "9     [(-1, 64, 32, 32)]      27712      2  \n",
      "10    [(-1, 64, 32, 32)]         64      2  \n",
      "11    [(-1, 64, 32, 32)]      27776      1  \n",
      "12    [(-1, 48, 32, 32)]       3120      2  \n",
      "13    [(-1, 48, 32, 32)]         48      2  \n",
      "14    [(-1, 48, 32, 32)]       3168      1  \n",
      "15    [(-1, 48, 33, 33)]          0      1  \n",
      "16    [(-1, 48, 32, 32)]          0      2  \n",
      "17    [(-1, 48, 32, 32)]          0      1  \n",
      "18    [(-1, 48, 32, 32)]       3120      2  \n",
      "19    [(-1, 48, 32, 32)]         48      2  \n",
      "20    [(-1, 48, 32, 32)]       3168      1  \n",
      "21    [(-1, 64, 32, 32)]      76864      2  \n",
      "22    [(-1, 64, 32, 32)]         64      2  \n",
      "23    [(-1, 64, 32, 32)]      76928      1  \n",
      "24    [(-1, 64, 32, 32)]       4160      2  \n",
      "25    [(-1, 64, 32, 32)]         64      2  \n",
      "26    [(-1, 64, 32, 32)]       4224      1  \n",
      "27   [(-1, 240, 32, 32)]     118432      0  \n",
      "28    [(-1, 64, 32, 32)]      15424      2  \n",
      "29    [(-1, 64, 32, 32)]         64      2  \n",
      "30    [(-1, 64, 32, 32)]      15488      1  \n",
      "31    [(-1, 92, 32, 32)]      53084      2  \n",
      "32    [(-1, 92, 32, 32)]         92      2  \n",
      "33    [(-1, 92, 32, 32)]      53176      1  \n",
      "34    [(-1, 64, 32, 32)]      15424      2  \n",
      "35    [(-1, 64, 32, 32)]         64      2  \n",
      "36    [(-1, 64, 32, 32)]      15488      1  \n",
      "37    [(-1, 64, 33, 33)]          0      1  \n",
      "38    [(-1, 64, 32, 32)]          0      2  \n",
      "39    [(-1, 64, 32, 32)]          0      1  \n",
      "40    [(-1, 64, 32, 32)]      15424      2  \n",
      "41    [(-1, 64, 32, 32)]         64      2  \n",
      "42    [(-1, 64, 32, 32)]      15488      1  \n",
      "43    [(-1, 92, 32, 32)]     147292      2  \n",
      "44    [(-1, 92, 32, 32)]         92      2  \n",
      "45    [(-1, 92, 32, 32)]     147384      1  \n",
      "46    [(-1, 92, 32, 32)]      22172      2  \n",
      "47    [(-1, 92, 32, 32)]         92      2  \n",
      "48    [(-1, 92, 32, 32)]      22264      1  \n",
      "49   [(-1, 340, 32, 32)]     269288      0  \n",
      "50   [(-1, 340, 16, 16)]          0      1  \n",
      "51   [(-1, 340, 16, 16)]          0      0  \n",
      "52    [(-1, 92, 16, 16)]      31372      2  \n",
      "53    [(-1, 92, 16, 16)]         92      2  \n",
      "54    [(-1, 92, 16, 16)]      31464      1  \n",
      "55   [(-1, 128, 16, 16)]     106112      2  \n",
      "56   [(-1, 128, 16, 16)]        128      2  \n",
      "57   [(-1, 128, 16, 16)]     106240      1  \n",
      "58    [(-1, 92, 16, 16)]      31372      2  \n",
      "59    [(-1, 92, 16, 16)]         92      2  \n",
      "60    [(-1, 92, 16, 16)]      31464      1  \n",
      "61    [(-1, 92, 17, 17)]          0      1  \n",
      "62    [(-1, 92, 16, 16)]          0      2  \n",
      "63    [(-1, 92, 16, 16)]          0      1  \n",
      "64    [(-1, 92, 16, 16)]      31372      2  \n",
      "65    [(-1, 92, 16, 16)]         92      2  \n",
      "66    [(-1, 92, 16, 16)]      31464      1  \n",
      "67   [(-1, 128, 16, 16)]     294528      2  \n",
      "68   [(-1, 128, 16, 16)]        128      2  \n",
      "69   [(-1, 128, 16, 16)]     294656      1  \n",
      "70   [(-1, 128, 16, 16)]      43648      2  \n",
      "71   [(-1, 128, 16, 16)]        128      2  \n",
      "72   [(-1, 128, 16, 16)]      43776      1  \n",
      "73   [(-1, 476, 16, 16)]     539064      0  \n",
      "74    [(-1, 92, 16, 16)]      43884      2  \n",
      "75    [(-1, 92, 16, 16)]         92      2  \n",
      "76    [(-1, 92, 16, 16)]      43976      1  \n",
      "77   [(-1, 128, 16, 16)]     106112      2  \n",
      "78   [(-1, 128, 16, 16)]        128      2  \n",
      "79   [(-1, 128, 16, 16)]     106240      1  \n",
      "80    [(-1, 92, 16, 16)]      43884      2  \n",
      "81    [(-1, 92, 16, 16)]         92      2  \n",
      "82    [(-1, 92, 16, 16)]      43976      1  \n",
      "83    [(-1, 92, 17, 17)]          0      1  \n",
      "84    [(-1, 92, 16, 16)]          0      2  \n",
      "85    [(-1, 92, 16, 16)]          0      1  \n",
      "86    [(-1, 92, 16, 16)]      43884      2  \n",
      "87    [(-1, 92, 16, 16)]         92      2  \n",
      "88    [(-1, 92, 16, 16)]      43976      1  \n",
      "89   [(-1, 128, 16, 16)]     294528      2  \n",
      "90   [(-1, 128, 16, 16)]        128      2  \n",
      "91   [(-1, 128, 16, 16)]     294656      1  \n",
      "92   [(-1, 128, 16, 16)]      61056      2  \n",
      "93   [(-1, 128, 16, 16)]        128      2  \n",
      "94   [(-1, 128, 16, 16)]      61184      1  \n",
      "95   [(-1, 476, 16, 16)]     594008      0  \n",
      "96     [(-1, 476, 8, 8)]          0      1  \n",
      "97     [(-1, 476, 8, 8)]          0      0  \n",
      "98      [(-1, 92, 8, 8)]      43884      2  \n",
      "99      [(-1, 92, 8, 8)]         92      2  \n",
      "100     [(-1, 92, 8, 8)]      43976      1  \n",
      "101    [(-1, 128, 8, 8)]     106112      2  \n",
      "102    [(-1, 128, 8, 8)]        128      2  \n",
      "103    [(-1, 128, 8, 8)]     106240      1  \n",
      "104     [(-1, 92, 8, 8)]      43884      2  \n",
      "105     [(-1, 92, 8, 8)]         92      2  \n",
      "106     [(-1, 92, 8, 8)]      43976      1  \n",
      "107     [(-1, 92, 9, 9)]          0      1  \n",
      "108     [(-1, 92, 8, 8)]          0      2  \n",
      "109     [(-1, 92, 8, 8)]          0      1  \n",
      "110    [(-1, 128, 8, 8)]      61056      2  \n",
      "111    [(-1, 128, 8, 8)]        128      2  \n",
      "112    [(-1, 128, 8, 8)]      61184      1  \n",
      "113    [(-1, 348, 8, 8)]     255376      0  \n",
      "114         [(-1, 1096)]   24412304      1  \n",
      "115         [(-1, 1096)]          0      1  \n",
      "116         [(-1, 1096)]   24412304      0  \n",
      "117         [(-1, 1096)]    1202312      1  \n",
      "118         [(-1, 1096)]          0      1  \n",
      "119         [(-1, 1096)]    1202312      0  \n",
      "120          [(-1, 180)]     197460      1  \n",
      "121          [(-1, 180)]          0      1  \n",
      "122          [(-1, 180)]     197460      0  \n",
      "123          [(-1, 180)]   27596372      0  \n"
     ]
    }
   ],
   "source": [
    "# attach temporary hooks using `with`\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "with TorchSummarizeDf(model) as tdf:\n",
    "    imgs = torch.zeros([n_batchs, img_channels,img_H ,img_W])\n",
    "    reds = torch.zeros([n_batchs,1])\n",
    "    y = model(imgs,reds)\n",
    "    df = tdf.make_df()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
